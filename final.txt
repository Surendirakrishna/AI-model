import speech_recognition as sr
from PIL import Image, ImageGrab
import cv2
import numpy as np
from collections import deque
import threading
import time
import os
import datetime
import wikipedia
import webbrowser
import pyperclip
import requests
from groq import Groq
import google.generativeai as genai
import json
from elevenlabs import generate, play, set_api_key, Voice, VoiceSettings
import spotipy
from spotipy.oauth2 import SpotifyOAuth
import pyautogui
from queue import Queue

# Initialize API clients
groq_client = Groq(api_key="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")
genai.configure(api_key="AIzaSyBBHKduJzWyDz68exvNe8zthJXOkzOdrVA")

# Set ElevenLabs API key
set_api_key("sk_185cb2b51d347ca6d46725fe6a989c79d1891a0b9750a7b3")

# Gemini Configuration
generation_config = {
    'temperature': 0.5,
    'top_p': 1,
    'top_k': 1,
}

safety_settings = [
    {'category': 'HARM_CATEGORY_HARASSMENT', 'threshold': 'BLOCK_NONE'},
    {'category': 'HARM_CATEGORY_HATE_SPEECH', 'threshold': 'BLOCK_NONE'},
    {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'threshold': 'BLOCK_NONE'},
    {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'threshold': 'BLOCK_NONE'}
]

model = genai.GenerativeModel(
    'gemini-1.5-flash-latest',
    generation_config=generation_config,
    safety_settings=safety_settings
)

class AudioProcessor:  
    def __init__(self):
        self.buffer = deque(maxlen=50)

    def filter_noise(self, audio_data):
        try:
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            self.buffer.extend(abs(audio_array))
            noise_floor = np.mean(list(self.buffer))
            filtered_data = np.where(
                abs(audio_array) > noise_floor * 1.2,
                audio_array,
                np.zeros_like(audio_array)
            )
            return filtered_data.tobytes()
        except Exception as e:
            print(f"Error in noise filtering: {e}")
            return audio_data

class VoiceAssistant:
    def __init__(self):
        self.recognizer = sr.Recognizer()
        self.audio_processor = AudioProcessor()
        self.configure_recognition()
        self.is_active = True
        # Initialize Gemini model for note generation
        self.note_model = genai.GenerativeModel('gemini-pro')
        
        # Initialize Spotify with better error handling and configuration
        try:
            auth_manager = SpotifyOAuth(
                client_id="ed672aee47f74b2fb812f523ccaa3a3e",
                client_secret="eafc40a977444422a954a45b3aa906a2",
                redirect_uri="http://localhost:8888/callback",
                scope=[
                    "user-read-playback-state",
                    "user-modify-playback-state",
                    "user-read-currently-playing",
                    "app-remote-control",
                    "streaming"
                ],
                open_browser=True  # This will help with authentication
            )
            self.spotify = spotipy.Spotify(auth_manager=auth_manager)
            # Test the connection
            self.spotify.current_user()  # This will verify if authentication works
            print("Spotify successfully connected!")
        except Exception as e:
            print(f"Spotify initialization error: {e}")
            self.spotify = None

        # Auto-typing configuration
        self.typing_active = False
        self.typing_speed = 0.01
        self.command_queue = Queue()
        
        # Safety configuration for pyautogui
        pyautogui.FAILSAFE = True
        pyautogui.PAUSE = 0.01

    def configure_recognition(self):
        """
        Configure speech recognition settings with standard parameters
        """
        # Standard energy threshold
        self.recognizer.energy_threshold = 4000  # Default value
        
        # Dynamic energy settings
        self.recognizer.dynamic_energy_threshold = True
        self.recognizer.dynamic_energy_adjustment_damping = 0.15
        self.recognizer.dynamic_energy_ratio = 1.5
        
        # Timing parameters
        self.recognizer.pause_threshold = 0.8
        self.recognizer.phrase_threshold = 0.3
        self.recognizer.non_speaking_duration = 0.5

    def speak(self, text):
        """
        Speak using ElevenLabs voice
        """
        try:
            print(f"Assistant: {text}")
            audio = generate(
                text=text,
                voice="Brian",  # Primary voice
                model="eleven_multilingual_v2"
            )
            play(audio, use_ffmpeg=False)
        except Exception as e:
            print(f"Error in speech generation: {e}")
            # Try another voice if Brian fails
            try:
                audio = generate(
                    text=text,
                    voice="Sarah",  # Fallback voice
                    model="eleven_multilingual_v2"
                )
                play(audio, use_ffmpeg=False)
            except Exception as e2:
                print(f"Fallback voice error: {e2}")
                print(f"Assistant (text only): {text}")

    def take_screenshot(self):
        try:
            screenshot = ImageGrab.grab()
            filename = f"screenshot_{int(time.time())}.png"
            screenshot.save(filename)
            return filename
        except Exception as e:
            print(f"Screenshot error: {e}")
            return None

    def capture_webcam(self):
        try:
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                raise Exception("Could not open webcam")
            ret, frame = cap.read()
            if not ret:
                raise Exception("Could not capture frame")
            filename = f"webcam_{int(time.time())}.png"
            cv2.imwrite(filename, frame)
            cap.release()
            return filename
        except Exception as e:
            print(f"Webcam capture error: {e}")
            return None

    def write_note(self, topic):
        """
        Generate and write a note about the given topic
        """
        try:
            # Generate the content
            prompt = f"Provide a detailed explanation about {topic}."
            response = self.note_model.generate_content(prompt)
            
            # Create unique filename
            filename = f'note_{int(time.time())}.txt'
            
            # Write to file
            with open(filename, 'w', encoding='utf-8') as file:
                file.write(f"Topic: {topic}\n\n")
                file.write("Content:\n")
                file.write(response.text)
            
            return filename
        except Exception as e:
            print(f"Error writing note: {e}")
            return None

    def vision_prompt(self, text_prompt, image_path):
        try:
            image = Image.open(image_path)
            response = model.generate_content([text_prompt, image])
            return response.text
        except Exception as e:
            print(f"Vision processing error: {e}")
            return None
        
    def groq_prompt(self, text, visual_context=None):
        try:
            messages = [
                {
                    "role": "system",
                    "content": (
                        "You are a helpful voice assistant, Created by surendira krishna. Provide clear and concise responses. "
                        "If visual context is provided, incorporate it into your response."
                        "Avoid unnecessary details."
                        "Be polite and respectful."
                        "Avoid detailed explaination."
                        "Provide extremely brief, direct responses. "
                        "Limit answers to 1 sentences max. "
                        "Be succinct and to the point. "
                        "Avoid elaboration or unnecessary details."
                    )
                },
                { 
                    "role": "user",
                    "content": text if not visual_context else f"{text}\nVisual context: {visual_context}"
                }
            ]
            response = groq_client.chat.completions.create(
            model="mixtral-8x7b-32768",
            messages=messages,
            temperature=0.7,
            max_tokens=150,
            top_p=1,
            stream=False
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"Groq API error: {e}")
            return None

    def wake_word_detected(self, text):
        if not text:
            return False
        wake_words = ["bay max", "baymax", "hey bay max", "hey baymax", "okay bay max", "okay baymax"]
        return any(wake_word in text.lower() for wake_word in wake_words)

    def function_call(self, text):
        text = text.lower()
        if 'write' in text and ('note' in text or 'about' in text):
            return 'write note'
        elif 'spotify' in text:
            return 'open spotify'
        elif 'screenshot' in text or 'screen' in text:
            return 'take screenshot'
        elif 'webcam' in text or 'camera' in text:
            return 'capture webcam'
        elif 'wikipedia' in text:
            return 'wikipedia'
        elif 'weather' in text:
            return 'weather'
        elif 'time' in text:
            return 'time'
        elif 'open' in text or 'play' in text:
            return 'open'
        elif any(word in text for word in ['play', 'pause', 'resume', 'next', 'previous', 'volume', 'current']):
            return 'spotify_control'
        return 'conversation'

    def control_spotify(self, command):
        if self.spotify is None:
            self.speak("Spotify is not properly connected. Please check your authentication.")
            return
            
        try:
            # Get available devices first
            devices = self.spotify.devices()
            if not devices['devices']:
                self.speak("No active Spotify devices found. Please open Spotify and try again.")
                return
                
            # Use the first available device
            device_id = devices['devices'][0]['id']
            
            if 'play' in command:
                search_query = command.replace('play', '').strip()
                if search_query:
                    try:
                        results = self.spotify.search(q=search_query, type='track', limit=1)
                        if results['tracks']['items']:
                            track_uri = results['tracks']['items'][0]['uri']
                            self.spotify.start_playback(device_id=device_id, uris=[track_uri])
                            track_name = results['tracks']['items'][0]['name']
                            artist_name = results['tracks']['items'][0]['artists'][0]['name']
                            self.speak(f"Playing {track_name} by {artist_name}")
                        else:
                            self.speak("Sorry, I couldn't find that song")
                    except spotipy.exceptions.SpotifyException as e:
                        print(f"Spotify playback error: {e}")
                        self.speak("There was an error playing the song. Make sure Spotify is open and active.")
            
            elif 'pause' in command:
                self.spotify.pause_playback()
                self.speak("Pausing music")
            
            elif 'resume' in command or 'continue' in command:
                self.spotify.start_playback()
                self.speak("Resuming music")
            
            elif 'next' in command:
                self.spotify.next_track()
                self.speak("Playing next track")
            
            elif 'previous' in command or 'last' in command:
                self.spotify.previous_track()
                self.speak("Playing previous track")
            
            elif 'volume' in command:
                # Extract volume level (0-100)
                try:
                    volume_level = int(''.join(filter(str.isdigit, command)))
                    if 0 <= volume_level <= 100:
                        self.spotify.volume(volume_level)
                        self.speak(f"Setting volume to {volume_level} percent")
                except:
                    self.speak("Please specify a volume level between 0 and 100")

            elif 'current' in command or 'what' in command and 'playing' in command:
                current_track = self.spotify.current_user_playing_track()
                if current_track:
                    track_name = current_track['item']['name']
                    artist_name = current_track['item']['artists'][0]['name']
                    self.speak(f"Currently playing {track_name} by {artist_name}")
                else:
                    self.speak("No track is currently playing")

        except Exception as e:
            print(f"Spotify control error: {e}")
            self.speak("I encountered an error controlling Spotify")

    def _type_character(self, char):
        """Handle special characters during typing."""
        if char == '\n':
            pyautogui.press('enter')
        elif char in '!@#$%^&*()_+{}|:"<>?~':
            pyautogui.keyDown('shift')
            pyautogui.press(char.lower())
            pyautogui.keyUp('shift')
        else:
            pyautogui.write(char)

    def _typing_thread(self, text):
        """Thread worker for typing with interrupt support."""
        self.typing_active = True
        try:
            for char in text:
                if not self.typing_active:
                    break
                self._type_character(char)
                time.sleep(self.typing_speed)
        finally:
            self.typing_active = False

    def auto_type_text(self, text):
        """Enhanced typing function with interrupt capability."""
        self.speak("Say 'start' to begin or 'cancel' to abort. You can say 'stop' during typing.")
        
        while True:
            try:
                with sr.Microphone() as source:
                    audio = self.recognizer.listen(source, timeout=5)
                    command = self.recognizer.recognize_google(audio).lower()
                    
                    if command == 'start':
                        self.speak("Starting in 3 seconds... Focus the text field!")
                        time.sleep(3)
                        
                        # Start typing thread
                        thread = threading.Thread(target=self._typing_thread, args=(text,))
                        thread.start()
                        
                        # Monitor for stop commands
                        while thread.is_alive():
                            try:
                                audio = self.recognizer.listen(source, timeout=1)
                                cmd = self.recognizer.recognize_google(audio).lower()
                                if cmd == 'stop':
                                    self.typing_active = False
                                    self.speak("Typing stopped.")
                                    break
                            except (sr.WaitTimeoutError, sr.UnknownValueError):
                                continue
                        thread.join()
                        break
                    elif command == 'cancel':
                        self.speak("Operation cancelled.")
                        break
                    else:
                        self.speak("Please say 'start' or 'cancel'.")
            except (sr.WaitTimeoutError, sr.UnknownValueError):
                continue
            except Exception as e:
                print(f"Error in auto_type: {e}")
                break

    def handle_command(self, command):
        try:
            call_type = self.function_call(command)
            visual_context = None

            if 'type' in command and ('explanation' in command or 'about' in command):
                # Extract the topic after "type explanation about" or similar phrases
                topic = command.lower().replace('type', '').replace('explanation', '').replace('about', '').strip()
                if topic:
                    self.speak(f"Generating explanation about {topic}")
                    prompt = f"Generate a concise programming explanation with example code for {topic}."
                    response = model.generate_content(prompt)
                    if response:
                        self.speak("Explanation ready.")
                        self.auto_type_text(response.text)
                    else:
                        self.speak("Sorry, I couldn't generate an explanation")
                else:
                    self.speak("What topic would you like an explanation about?")
                return

            if call_type == 'write note':
                # Extract the topic after "write note about" or similar phrases
                topic = command.lower().replace('write', '').replace('note', '').replace('about', '').strip()
                if topic:
                    self.speak(f"Writing a note about {topic}")
                    filename = self.write_note(topic)
                    if filename:
                        self.speak(f"I've written the note and saved it as {filename}")
                        # Open the file in notepad (Windows only)
                        try:
                            os.system(f'notepad.exe {filename}')
                        except:
                            pass
                    else:
                        self.speak("Sorry, I couldn't write the note")
                else:
                    self.speak("What would you like me to write about?")

            elif call_type == 'open spotify':
                try:
                    os.system('start spotify:')
                    self.speak("Opening Spotify")
                except Exception as e:
                    print(f"Error opening Spotify: {e}")
                    self.speak("I couldn't open Spotify")

            elif call_type == 'take screenshot':
                self.speak('Taking screenshot...')
                photo_path = self.take_screenshot()
                if photo_path:
                    visual_context = self.vision_prompt("Describe what you see in this screenshot in 1-2 sentence", photo_path)
                    self.speak(visual_context if visual_context else "I captured the screenshot but couldn't analyze it.")

            elif call_type == 'capture webcam':
                self.speak('Capturing from webcam...')
                photo_path = self.capture_webcam()
                if photo_path:
                    visual_context = self.vision_prompt("Describe what you see in this webcam image in 1 sentense", photo_path)
                    self.speak(visual_context if visual_context else "I captured the image but couldn't analyze it.")

            elif call_type == 'open':
                if 'youtube' in command:
                    if 'play' in command and 'song' in command:
                        search_query = command.split('play')[-1].replace('song', '').strip()
                        if not search_query and 'tamil' in command:
                            search_query = 'latest tamil songs'
                        url = f"https://www.youtube.com/results?search_query={search_query.replace(' ', '+')}"
                        webbrowser.open_new_tab(url)
                        self.speak(f"Opening YouTube and searching for {search_query}")
                    else:
                        webbrowser.open_new_tab("https://www.youtube.com")
                        self.speak("Opening YouTube")
                elif 'google' in command:
                    search_query = command.split('search')[-1].strip()
                    if search_query:
                        url = f"https://www.google.com/search?q={search_query.replace(' ', '+')}"
                        webbrowser.open_new_tab(url)
                        self.speak(f"Searching Google for {search_query}")
                    else:
                        webbrowser.open_new_tab("https://www.google.com")
                        self.speak("Opening Google")

            elif call_type == 'time':
                current_time = datetime.datetime.now().strftime("%I:%M %p")
                self.speak(f"The current time is {current_time}")
                return

            elif call_type == 'wikipedia':
                query = command.replace('wikipedia', '').strip()
                self.speak('Searching Wikipedia...')
                try:
                    result = wikipedia.summary(query, sentences=1)
                    self.speak(result)
                except:
                    self.speak("I couldn't find that on Wikipedia")

            elif call_type == 'spotify_control':
                self.control_spotify(command)

            elif call_type == 'conversation':
                response = self.groq_prompt(command, visual_context)
                if response:
                    self.speak(response)
                else:
                    self.speak("I'm sorry, I couldn't process that request.")

        except Exception as e:
            print(f"Error handling command: {e}")
            self.speak("I encountered an error processing that request.")

    def run(self):
        print("Voice Assistant Ready. Say 'Bay Max' to wake up.")

        with sr.Microphone() as source:  # Removed sample_rate parameter
            print("Calibrating microphone for ambient noise...")
            self.recognizer.adjust_for_ambient_noise(
                source, 
                duration=2  # Standard calibration period
            )
            print("Ready! Listening for wake word...")

            while self.is_active:
                try:
                    print("Listening for voice input...")
                    audio = self.recognizer.listen(
                        source,
                        timeout=5,  # Standard timeout
                        phrase_time_limit=10  # Standard phrase time limit
                    )
                    
                    wake_word = self.recognizer.recognize_google(
                        audio,
                        language='en-US',
                        show_all=False
                    ).lower()

                    if self.wake_word_detected(wake_word):
                        self.speak("Hello! How can I help you?")
                        
                        while True:
                            try:
                                print("Listening for command...")
                                audio = self.recognizer.listen(
                                    source, 
                                    timeout=5,
                                    phrase_time_limit=10
                                )
                                command = self.recognizer.recognize_google(
                                    audio, 
                                    language='en-US'
                                ).lower()
                                print(f"You said: {command}")

                                if self.wake_word_detected(command):
                                    self.speak("Starting new conversation")
                                    break

                                if "goodbye" in command or "bye" in command:
                                    self.speak("Goodbye!")
                                    return

                                self.handle_command(command)

                            except sr.WaitTimeoutError:
                                break
                            except sr.UnknownValueError:
                                self.speak("I didn't catch that. Could you please repeat?")
                            except Exception as e:
                                print(f"Error in conversation: {e}")
                                break

                except sr.WaitTimeoutError:
                    continue
                except sr.UnknownValueError:
                    continue
                except KeyboardInterrupt:
                    self.speak("Goodbye!")
                    break
                except Exception as e:
                    print(f"Error: {e}")
                    continue

    def _del_(self):
        """
        Clean up resources
        """
        try:
            if hasattr(self, 'spotify') and self.spotify is not None:
                self.spotify = None
        except Exception as e:
            print(f"Cleanup error: {e}")
            pass

if __name__ == "__main__":
    assistant = VoiceAssistant()
    assistant.run()
    